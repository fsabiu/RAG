{
    "chunking": {
      "STRATEGY": "semantic",
      "CHUNK_SIZE": 1000,
      "CHUNK_OVERLAP": 200
    },
    "chat_model": {
      "PROVIDER": "oci",
      "MODEL_ID": "cohere.command-r-plus",
      "TEMPERATURE": 0.0,
      "MAX_TOKENS": 4000,
      "TOP_P": 0.75,
      "OCI_COMPARTMENT_ID": "ocid1.compartment.oc1..aaaaaaaaq3jw5diyfz3ykg5ow76q6nvslelmx75nlg55xzdhfuzbikq77nda",
      "OCI_GENAI_ENDPOINT": "https://inference.generativeai.eu-frankfurt-1.oci.oraclecloud.com",
      "OCI_CONFIG_PROFILE": "IDIKA",
      "OCI_CONFIG_PATH": "~/.oci/config",
      "OCI_DEFAULT_MODEL": "cohere.command-r-plus"
    },
    "embedding_model": {
      "PROVIDER": "ollama",
      "MODEL_NAME": "mxbai-embed-large",
      "EMBEDDING_DIMENSION": 1024,
      "OLLAMA_HOST": "10.0.0.135",
      "OLLAMA_PORT": 11434
    },
    "vector_store": {
      "DEFAULT_PROVIDER": "Chroma",
      "CHROMA_PERSIST_DIRECTORY": "./chroma_db",
      "DOMAIN_CONFIG": {
        "example_domain": "chroma"
      }
    },
    "query_engine": {
      "USE_QUERY_OPTIMIZER": true,
      "USE_RESULT_RE_RANKER": true
    },
    "document": {
      "IMPLEMENTATION": "Python",
      "DB_CONNECTION_STRING": null
    },
    "DATA_FOLDER": "/path/to/data"
  }
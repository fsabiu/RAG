{
    "template": {
        "chunking": {
            "STRATEGY": "fixed",
            "CHUNK_SIZE": 1000,
            "CHUNK_OVERLAP": 200,
            "MAX_CHUNK_SIZE": 1200
        },
        "query_engine": {
            "USE_QUERY_OPTIMIZER": true,
            "USE_RESULT_RE_RANKER": true
        },
        "chat_model": {
            "PROVIDER": "oci",
            "MODEL_ID": "cohere.command-r-plus",
            "TEMPERATURE": 0.01,
            "MAX_TOKENS": 4000,
            "TOP_P": 0.75
        },
        "embedding_model": {
            "PROVIDER": "ollama",
            "MODEL_NAME": "mxbai-embed-large",
            "EMBEDDING_DIMENSION": 1024,
            "OLLAMA_HOST": "10.0.0.135",
            "OLLAMA_PORT": 11434
        },
        "vector_store": {
            "DEFAULT_PROVIDER": "Chroma"
        },
        "document": {
            "IMPLEMENTATION": "Python",
            "DB_CONNECTION_STRING": null
        }
    },
    "metadata": {
        "labels": {
            "EN": {
                "chunking": "Chunking",
                "chunking.STRATEGY": "Chunking Strategy",
                "chunking.CHUNK_OVERLAP": "Chunks overlap",
                "chunking.CHUNK_SIZE": "Chunks size",
                "chunking.MAX_CHUNK_SIZE": "Maximum chunk size",
                "query_engine": "Query Engine",
                "query_engine.USE_QUERY_OPTIMIZER": "Query optimizer",
                "query_engine.USE_RESULT_RE_RANKER": "Query reranker",
                "chat_model": "Chat Model",
                "chat_model.TEMPERATURE": "Temperature",
                "chat_model.MODEL_ID": "Model ID",
                "chat_model.MAX_TOKENS": "Max tokens",
                "chat_model.TOP_P": "Top P",
                "chat_model.PROVIDER": "Chat Model Provider",
                "embedding_model": "Embedding Model",
                "embedding_model.PROVIDER": "Embedding Model Provider",
                "embedding_model.MODEL_NAME": "Embedding Model Name",
                "embedding_model.EMBEDDING_DIMENSION": "Embedding Dimensions",
                "embedding_model.OLLAMA_HOST": "Ollama host",
                "embedding_model.OLLAMA_PORT": "Ollama port",
                "vector_store": "Vector Store",
                "vector_store.DEFAULT_PROVIDER": "Default Vector Store Provider",
                "vector_store.DOMAIN_CONFIG": "Domain-specific Vector Store",
                "document": "Document",
                "document.IMPLEMENTATION": "Document Implementation"
            }
        },
        "config": {
            "chunking": {
                "STRATEGY": {
                    "allowed_values": ["fixed", "semantic"],
                    "dependencies": {
                        "fixed": ["CHUNK_OVERLAP", "CHUNK_SIZE"],
                        "semantic": ["MAX_CHUNK_SIZE"]
                    }
                }
            },
            "chat_model": {
                "PROVIDER": {
                    "allowed_values": ["oci"],
                    "dependencies": {
                        "oci": ["MODEL_ID", "TEMPERATURE", "MAX_TOKENS", "TOP_P"]
                    }
                }
            },
            "embedding_model": {
                "PROVIDER": {
                    "allowed_values": ["ollama", "cohere"],
                    "dependencies": {
                        "ollama": ["MODEL_NAME", "EMBEDDING_DIMENSION", "OLLAMA_HOST", "OLLAMA_PORT"],
                        "cohere": {
                            "MODEL_NAME": ["embed-english-v3.0"]
                        }
                    }
                }
            },
            "vector_store": {
                "DEFAULT_PROVIDER": {
                    "allowed_values": ["Chroma", "Oracle23ai"]
                }
            },
            "document": {
                "IMPLEMENTATION": {
                    "allowed_values": ["OCI_DB", "Python"],
                    "dependencies": {
                        "OCI_DB": ["DB_CONNECTION_STRING"]
                    }
                }
            }
        }
    }
}